---
title: "Movie Recommendation System"
subtitle: "Predicting Movie Ratings"
author: "Nimisha Agrawal"
date: "January 1, 2021"
abstract: This project seeks to implement two movie recommendation systems to predict the rating of a movie by a user. The first model uses a handcrafted hybrid method that models user-movie interactions and movies' attributes. The second model uses a collaborative filtering method via matrix factorization as done by the recosystem package. The report starts with an introduction to the basics of recommender systems. Next is a description of the data set followed by the menthodology and the procedure for data wrangling and pre-processing. Some exploratory data analysis has been done to understand the dataset and draw helpful insights. Then the evolution of our machine learning models has been described in detail. Finally, the results (including RMSE values) and the conclusion is presented, with a future outlook. 
output: 
  pdf_document:
    toc: true
---

```{r setup, include=FALSE}
#!!!!!!DO NOT RUN/KNIT FILE IF RAM LESS THAN 16GB!!!!!!
#setting global options common to all R chunks
knitr::opts_chunk$set(
  echo=TRUE, message=FALSE, warning=FALSE, eval=TRUE)
```

```{r installing-packages, include=FALSE}
#!!!!!!DO NOT RUN/KNIT FILE IF RAM LESS THAN 16GB!!!!!!
#Throughout this process, data frames and variables created in the global 
#environment are removed after saving the necessary ones. This code is 
#memory-critical and every effort has been made to #save space.

#PACKAGES NEEDED FOR THE REPORT
if(!require(rmarkdown)) install.packages(
  "rmarkdown", repos = "http://cran.us.r-project.org")
if(!require(knitr)) install.packages(
  "knitr", repos = "http://cran.us.r-project.org")
if(!require(kableExtra)) install.packages(
  "kableExtra", repos = "http://cran.us.r-project.org")
if(!require(tinytex)) install.packages(
  "tinytex", repos = "http://cran.us.r-project.org")
#for installing TinyTeX (LaTeX distribution) using the 
#tinytex R package
tinytex::install_tinytex() 

#PACKAGES NEEEDED FOR THE CODE
if(!require(tidyverse)) install.packages(
  "tidyverse", repos = "http://cran.us.r-project.org") 
if(!require(caret)) install.packages(
  "caret", repos = "http://cran.us.r-project.org") 
if(!require(data.table)) install.packages(
  "data.table", repos = "http://cran.us.r-project.org") 
if(!require(lubridate)) install.packages(
  "lubridate", repos = "http://cran.us.r-project.org") 
if(!require(ggcorrplot)) install.packages(
  "ggcorrplot", repos = "http://cran.us.r-project.org") 
if(!require(randomcoloR)) install.packages(
  "randomcoloR", repos = "http://cran.us.r-project.org")
if(!require(ggridges)) install.packages(
  "ggridges", repos = "http://cran.us.r-project.org")
if(!require(recosystem)) install.packages(
  "recosystem", repos = "http://cran.us.r-project.org")
```

\newpage
# Introduction to Recommender Systems

Before I begin the technical description of recommender systems, consider this: in October 2006, Netflix offered **a million dollars** to anybody who could improve their recommendation system by 10%.^[https://www.netflixprize.com/] Okay, now let's delve in.    

Recommender systems essentially suggest relevant items to users. This is beneficial to both the users and the businesses. With a fitting recommender system, users get a personalized experience tailored to their preferences and interactions. For businesses, such personalisation enhances user engagement and consequently revenue. Win-win!  
Technically speaking, recommender systems can be divided into three categories:^[Suggested readings: https://towardsdatascience.com/introduction-to-recommender-systems-6c66cf15ada and https://lionbridge.ai/articles/step-by-step-guide-to-building-a-movie-recommendation-system/]     

* Content-based Methods: Movie attributes are used as inputs and movies similar to the user's past preferences are recommended.
* Collaborative Filtering Methods: Based on past interactions between users and movies, a user is recommended movies depending on the preferences of other similar users. (In our recosystem method of matrix factorization, only user-movie interactions are used to model the system.)
* Hybrid Methods: Combining content-based and collaborative filtering methods. (In our handcrafted method, we model both  movies' attributes and user-movie interactions.)     

Most modern systems use a hybrid model since they incorporate more attributes and consequently account for more variability, thus reducing RMSE which is our ultimate goal. (Computational time is another story.)    

\newpage
# The Data Set

In this project, the [Movie Lens 10M Dataset](https://grouplens.org/datasets/movielens/10m/)^[Thanks to Rich Davies for generating the data set.] is used. [Movielens](https://movielens.org/) is an online 'non-commercial, personalized' movie recommender service. The main Movielens data set^[F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4, Article 19 (December 2015), 19 pages. DOI = http://dx.doi.org/10.1145/2827872] has 27 million ratings. The one used here is a randomly selected subset containing about 10 million ratings for 10,681 movies by 71,567 users of Movielens. Of the three files in the dataset, we use only *ratings.dat* and *movies.dat*. We ignore tags.dat to reduce computational complexity.    

\newpage
# Methodology

I use R^[R is free and open source. You can download it here: https://cran.r-project.org/] with the RStudio IDE^[RStudio has many useful features apart from the editor. You can download it here: https://rstudio.com/products/rstudio/download/] to perform data wrangling, pre-processing, exploratory analysis and machine learning. This report is generated using [R Markdown with RStudio](https://rmarkdown.rstudio.com/), in a [Tufte Handout](https://rstudio.github.io/tufte/) format.  
To implement the project, the following packages are used in addition to base R:    

```{r loading-packages, results='hide'}
#PACKAGES FOR THE REPORT:
library(rmarkdown) #converting R markdown documents into several formats
library(knitr) #a general-purpose package for dynamic report generation
library(kableExtra) #nice table generator
library(tinytex) #for compiling from .Rmd to .pdf

#PACKAGES FOR THE CODE:
library(tidyverse) #for data processing and analysis
library(caret) #for splitting data for machine learning
library(data.table) #for data wrangling
library(lubridate) #for dealing with date-time attributes
library(ggcorrplot) #for plotting the correlation matrix
library(randomcoloR) #to generate a discrete color palette
library(ggridges) #for making ridges density plots
library(recosystem) #for implementing matrix factorization
```

\newpage
# Data Wrangling

Data wrangling is the process of converting raw data into tidy form. The database is downloaded into a temporary file. The delimited^[Data in the files provided is separated using :: as delimiter.] files *ratings.dat* and *movies.dat* are read and converted into data frames.     

```{r wrangling1, results='hide'}
#downloading the file into a temporary file
dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip",dl)

#.dat files have :: as column separators
#gsub replaces all :: with a tab so that the data can be easily read into a table
#with the friendly fread 
ratings <- fread(text = gsub("::", "\t", 
                             readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 col.names = c("userId", "movieId", "rating", "timestamp"))

#reading in movies data and making a data frame
movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")),"\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")

#if using R 3.6 or earlier:
#movies <- as.data.frame(movies) %>% 
#  mutate(
#    movieId = as.numeric(levels(movieId))[movieId],
#    title = as.character(title),
#    genres = as.character(genres))

#if using R 4.0 or later:
movies <- as.data.frame(movies) %>% 
  mutate(movieId = as.numeric(movieId),
         title = as.character(title),
         genres = as.character(genres))
```

The movie information is joined to the rating information for the corresponding movies resulting in the final *movielens* data set that we will split into test and training sets.     

```{r wrangling2, results='hide'}
#to keep only the movies with corresponding entries in ratings and combine the 
#tables' columns, ratings data is left joined to movie data, resulting into a new
#'movielens' data set
movielens <- left_join(ratings, movies, by = "movieId")
```

\newpage
# Pre-processing

The *movielens* data set created after wrangling is first split into test (*edx*) and training (*temp*) sets using the *createDataPartition* function of the *caret* package. The sets are then modified to ensure that the final test set (*validation*) only has users and movies which are present in the training set.    

```{r pre-processing1, results='hide'}
#SPLITTING THE DATA

#validation set will be 10% of movieLens data
set.seed(1, sample.kind="Rounding") 
#if using R 3.5 or earlier, use `set.seed(1)`

test_index <- createDataPartition(
  y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,] #training set
temp <- movielens[test_index,] #a temporary validation set

#to make sure userId and movieId in validation set are also in edx set, 
#semi-join returns rows from the temporary validation set that have a match in 
#the training set 'edx'
validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

#adding rows removed from the temporary validation set back into the edx set
removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)
```

```{r pre-processing1a, include=FALSE}
#creating new directory within working directory to save the data sets generated
dir.create(file.path(getwd(),"rda")) 

#saving the test set 'validation' to use later
save(validation, file="rda/validation.rda")

#removing variables not needed for now to save memory
rm(dl, ratings, movies, test_index, temp, movielens, removed, validation)

#clearing out memory since the program is memory-critical
gc() 
```

Some additional columns are created in the training set which extract information from existing columns and make it more usable for machine learning. Columns thereby rendered redundant are removed. This has also been done correspondingly in the validation set to allow for smooth testing.     

```{r pre-processing2, results='hide'}
#PRE-PROCESSING THE EDX DATA SET

#extracting day, month and year of rating from timestamp, 
#extracting movie release year from the title, and
#subtracting year of rating from the movie release year to get years lapsed
#also, removing title and timestamp columns since all info extracted from them
edx <- edx %>% 
  mutate(month_rating = month(as_datetime(timestamp)),
         day_rating = as.numeric(factor(weekdays(as_datetime(timestamp)),
                                        levels = c("Monday", "Tuesday", "Wednesday",
                                                   "Thursday", "Friday", "Saturday",
                                                   "Sunday"))),
         year_movie = as.numeric(str_sub(title,-5,-2)),
         years_lapsed = year(as_datetime(timestamp))-year_movie) %>%
  select(-c("title", "timestamp"))

#to extract genre data, getting each genre in separate row
edx_genre_separated <- edx %>% separate_rows(genres, sep="\\|")

#getting the average rating and count stats for every genre
genres_stats <- edx_genre_separated %>% 
  group_by(genres) %>% 
  summarise(avg_rating=mean(rating), n=n())

#to add genre characteristic rating, adding a column with the maximum of the 
#average ratings of the genres of the movie (rounded)
edx <- edx_genre_separated %>% 
  group_by(userId, movieId) %>% 
  left_join(genres_stats) %>% 
  summarize(genres_rating=round(max(avg_rating),1)) %>% 
  right_join(edx) %>%
  ungroup() %>%
  select(-genres) #genres column not needed anymore
```

```{r pre-processing2a, include=FALSE}
#saving data sets to be used later
save(edx_genre_separated, file="rda/edx_genre_separated.rda")
save(genres_stats, file="rda/genres_stats.rda")
save(edx, file="rda/edx_final.rda")

#removing unnecessary data sets to save memory
#kept genres_stats to use for the validation set
rm(edx_genre_separated, edx)

gc() #clearing out memory

#PRE-PROCESSING VALIDATION DATA IN ACCORDANCE WITH EDX DATA
#re-loading the validation data set
load("rda/validation.rda")
```


```{r pre-processing2b, results='hide'}
#PRE-PROCESSING VALIDATION DATA IN ACCORDANCE WITH EDX DATA
#the columns that were added in edx are added here too.
#columns removed in edx are removed here too
validation <- validation %>% 
  mutate(month_rating = month(as_datetime(timestamp)),
         day_rating = as.numeric(factor(weekdays(as_datetime(timestamp)),
                                        levels=c("Monday", "Tuesday", "Wednesday",
                                                 "Thursday", "Friday", "Saturday",
                                                 "Sunday"))),
         year_movie = as.numeric(str_sub(title,-5,-2)),
         years_lapsed = year(as_datetime(timestamp))-year_movie) %>%
  select(-c("title", "timestamp"))

#extracting the genres by separating rows and adding on the genres_rating stats 
#using the avg_rating from the previously created genre_stats data set
#**The validation ratings have NOT been used in any manner here.
validation <- validation %>% 
  separate_rows(genres, sep="\\|") %>%
  group_by(userId, movieId) %>% 
  left_join(genres_stats) %>% 
  summarize(genres_rating=round(max(avg_rating),1)) %>% 
  right_join(validation) %>%
  ungroup() %>%
  select(-genres)
```


```{r pre-processing2c, include=FALSE}
#saving the new validation data to use for testing later
save(validation, file="rda/validation_final.rda")

#removing validation and genres_stats data sets 
#as they are not needed for now
rm(validation, genres_stats)

gc() #clearing out memory
```

\newpage
# Exploratory Data Analysis

## Basic Analysis

To begin our exploration of the *edx* training set, here's a table of what the column names mean:    

Column Name | Explanation
------------- | -------------------------------------------
userId | Unique ID for the user
movieId | Unique ID for the movie
genres_rating | Maximum of the average ratings of the genres of the movie
rating | A rating between 0 and 5 for the movie in increments of 0.5
month_rating | The month in which the rating was given where 1 is January, 2 is February and so on.
day_rating | The day of the week in which the rating was given where 1 is Monday, 2 is Tuesday and so on.
year_movie | The year in which the movie released.
years_lapsed | The year gap between movie released and rating given.     

```{r analysis0, include=FALSE}
load("rda/edx_final.rda")
```


Now, let's look at the basic structure of the *edx* data set:    

```{r analysis1a}
str(edx)
summary(edx)
```

Here's a sneak peek of the first few rows of the *edx* data set:    

```{r analysis1b, echo=FALSE}
#Using kbl to create a nice table:
kbl(head(edx), longtable=T, booktabs=T, caption="First 6 Rows of edx (train set)") %>%
  column_spec(1:8, width="1.5cm") %>%
  kable_styling(latex_options=c("repeat_header")) %>%
  row_spec(0, angle= 30)
```

There are `r length(unique(edx$movieId))` unique movies and `r length(unique(edx$userId))` unique users who have rated movies.    

Now let's go through a few visuals^[The plots have been constructed using the *ggplot2* package.] to better understand the data and maybe find something interesting?    

\newpage
## Standalone Variable Analysis

First, the different variables are analyzed standalone.    

```{r analysis2a, echo=FALSE, out.width='75%', fig.align = 'center'}
#barplot of the count of ratings
edx %>% ggplot(aes(rating)) + 
  geom_bar(fill="royalblue4") +
  labs(x="Rating", 
       y="Count",
       title="Distribution of Ratings") +
  theme_bw()
```

It is immediately obvious that whole number ratings are much more common than the half number ones. Because of this disparity, I will round the ratings to whole numbers in future analyses. It is also worth noting that 4 star ratings are the most common and that users rarely give the lowest rating. Guess we do love all movies then?  

```{r analysis2b, echo=FALSE, fig.show="hold", out.width="50%"}
#checking the distribution of the features
edx %>% ggplot(aes(userId)) +
  geom_histogram(fill="royalblue4") +
  labs(x="User ID",
       y="Count",
       title="Distribution of User ID") +
  theme_bw()

edx %>% ggplot(aes(movieId)) +
  geom_histogram(fill="royalblue4") +
  labs(x="Movie ID",
       y="Count",
       title="Distribution of Movie ID") +
  theme_bw()

edx %>% ggplot(aes(month_rating)) +
  geom_histogram(fill="royalblue4") +
  labs(x="Month of Rating (Jan to Dec)",
       y="Count",
       title="Distribution of Month of Rating") +
  theme_bw()

edx %>% ggplot(aes(day_rating)) +
  geom_histogram(fill="royalblue4") +
  labs(x="Day of Rating (Mon to Sun)",
       y="Count",
       title="Distribution of Day of Rating") +
  theme_bw()

edx %>% ggplot(aes(year_movie)) +
  geom_histogram(fill="royalblue4") +
  labs(x="Year Movie Release",
       y="Count",
       title="Distribution of Year of Movie Release") +
  theme_bw()

edx %>% ggplot(aes(years_lapsed)) +
  geom_histogram(fill="royalblue4") +
  labs(x="Years Lapsed",
       y="Count",
       title="Distribution of Years Lapsed") +
  theme_bw()

edx %>% ggplot(aes(genres_rating)) +
  geom_histogram(fill="royalblue4") +
  labs(x="Max Average Rating of Genres",
       y="Count",
       title="Distribution of Max Average Rating of Genres") +
  theme_bw()
```

Firstly, contrary to what I think, lesser movies are rated on weekends. Second, people have rated and watched more movies in November-December (probably because a lot of time is spent indoors for the northern hemisphere people in winters?). Third, the distribution of movieId shows that majority of the people have rated a few movies (probably the blockbusters). Most other movie ratings are scarce. Fourth, all users have rated about the same number of movies. And finally, most of the movies in our dataset are relatively new and have been rated without much delay.   

\newpage
## Correlation Analysis

Next, the variables are checked for correlations.  

```{r analysis3a, echo=FALSE, out.width='75%', fig.align = 'center'}
#checking correlations of all the variables
corr <- round(cor(edx),1)
p.mat <- cor_pmat(edx)
ggcorrplot(corr, hc.order = TRUE, type = "lower", lab = TRUE, p.mat = p.mat) +
  labs(title="Pearson correlation Heatmap")
```

```{r analysis3b, include=FALSE}
rm(corr, p.mat) #removing variables not needed
gc() #clearing the memory
```

The X indicates that the p-value of the correlation is insignificant (95% C.I.). The correlations are negligible, except where a variable is explicitly used to compute another (like year_movie for years_lapsed and rating for genres_rating).  

\newpage
## Outcome (rating) Analysis with Features

What follows is an exhaustive analysis of the outcome *rating* with the features.  

```{r analysis4a, echo=FALSE, out.width='75%', fig.align = 'center'}
#ANALYZING HOW RATINGS VARY WITH THE FEATURES
#checking the variation of ratings with time
edx %>% ggplot(aes(x = (years_lapsed + year_movie),y=factor(round(rating)))) + 
  geom_density_ridges(fill="royalblue4", col="grey") +
  labs(x="Year of Rating", 
       y="Rating (rounded)",
       title="Density Plots of Ratings over the Years") +
  theme_bw()
```

From the plot, two things are obvious. First, the lowest ratings have only come up in recent times. (So people were mostly satisfied with what they had in the old days?) Second, while the proportion of highest ratings (5) has decreased with time, that of medium-high ratings (4) has increased. (It's easier to get people to like you than to love you?)  

```{r analysis4b, echo=FALSE, out.width='75%', fig.align = 'center'}
#ANALYZING HOW RATINGS VARY WITH THE FEATURES
#checking the variation of ratings with the month
edx %>% ggplot(aes(x=rating, y=factor(month_rating))) + 
  geom_density_ridges(fill="royalblue4", col="grey") +
  labs(x="Rating (rounded)", 
       y="Month of Rating (Jan to Dec)",
       title="Density Plots of Month of Rating vs. Rating") +
  theme_bw()
```

The distribution of ratings is roughly the same every month and follows the overall trend of the rating distributions.     

```{r analysis4c, echo=FALSE, out.width='75%', fig.align = 'center'}
#ANALYZING HOW RATINGS VARY WITH THE FEATURES
#checking the variation of ratings with the day of the week
edx %>% ggplot(aes(x=rating, y=factor(day_rating))) + 
  geom_density_ridges(fill="royalblue4", col="grey") +
  labs(x="Rating (rounded)", 
       y="Day of Rating (Mon to Sun)",
       title="Density Plots of Day of Rating vs. Rating") +
  theme_bw()
```

The distribution of ratings is roughly the same every day of the week and follows the overall trend of the rating distributions.  

```{r analysis4d, echo=FALSE, out.width='75%', fig.align = 'center'}
#ANALYZING HOW RATINGS VARY WITH THE FEATURES
#checking the variation of ratings with movie release year
#fct_rev (factor reverse) is used for 0 ratings in the bottom
#direction argument in scale_fill_brewer changes the order of palette colours
edx %>% 
  ggplot(aes(year_movie, fill= fct_rev(factor(round(rating))))) + 
  geom_density(position="fill", adjust=7) + 
  scale_fill_brewer(palette="RdBu", direction=-1) + 
  labs(x="Year of Movie Release", 
       y="Density",
       title="Stacked Density Plot of Movie Release Year, filled by Rating",
       fill="Rating\n(rounded)") +
  theme_bw()
```

It is seen that a higher proportion of older movies were given the highest rating as compared to newer movies. The lowest ratings witnessed a dip from the 1930s to the 2000s. (Probably because older movies are scarcely watched and that too only by the willing, and they either love it or hate it.)  

```{r analysis4e, echo=FALSE, out.width='75%', fig.align = 'center'}
#ANALYZING HOW RATINGS VARY WITH THE FEATURES
#checking the variation of ratings with years lapsed
#fct_rev (factor reverse) is used for 0 ratings in the bottom
#direction argument in scale_fill_brewer changes the order of palette colours
edx %>% 
  ggplot(aes(years_lapsed, fill= fct_rev(factor(round(rating))))) + 
  geom_density(position="fill", adjust=7) + 
  scale_x_reverse() + 
  scale_fill_brewer(palette="RdBu", direction=-1) + 
  labs(x="Years Lapsed since Movie Release", 
       y="Density",
       title="Stacked Density Plot of Years Lapsed, filled by Rating",
       fill="Rating\n(rounded)") +
  theme_bw()
```

Keeping with the preceding explanation, it is seen that when people watch movies after a long time lapse, they either love it (highest rating) or hate it (lowest rating) with hardly any intermediates.      

\newpage
## Bonus: Genre Analysis

Presented below is a fun genre analysis purely for the purpose of exploration.  

```{r analysis5a, include=FALSE}
#GENRE ANALYSIS
#I will temporarily offload the edx data set and use the edx_genre_separated 
#data set that was generated earlier
rm(edx)
gc()
load("rda/edx_genre_separated.rda")
```

There are `r n_distinct(edx_genre_separated$genres)-1` distinct genres in the training set. There are also `r sum(edx_genre_separated$genres=="(no genres listed)")` entries for which no genre has been mentioned.  

```{r analysis5b, echo=FALSE, out.width='75%', fig.align = 'center'}
#GENRE ANALYSIS
#analysis of distribution of genres
#also analysing the distributions of ratings within genres
edx_genre_separated %>% 
  ggplot(aes(fct_rev(genres), fill=fct_rev(factor(round(rating))))) +
  geom_bar() +
  scale_fill_brewer(palette="RdBu", direction=-1) + 
  labs(x="Genres", 
       y="Count",
       title="Distribution of Genres, filled by Rating",
       fill="Rating\n(rounded)") +
  theme_bw() +
  coord_flip()
```

Drama is the most common genre, followed by comedy, action and thriller. The distribution of ratings within genres appears uniform across genres.      

```{r analysis5c, echo=FALSE, out.width='75%', fig.align = 'center'}
#GENRE ANALYSIS
palette1 <- distinctColorPalette(20) #generating a palette of 20 distinct colours
#analysis of distribution of genres within ratings
edx_genre_separated %>% 
  ggplot(aes(factor(round(rating)), fill=genres)) +
  geom_bar(position = "fill") + 
  scale_fill_manual(values=palette1) +
  theme(legend.title = element_blank()) +
  labs(x="Rating (rounded)", 
       y="Count",
       title="Distribution of Genres within Ratings",
       fill="Genres") +
  guides(fill = guide_legend(nrow = 11)) +
  theme_bw() 
```

There is a higher proportion of drama movies amongst the highest rated movies. Correspondingly, they have a lower proportion of action movies. the other genres are uniformly distributed within ratings.    

```{r analysis5d, echo=FALSE, out.width='75%', fig.align = 'center'}
#GENRE ANALYSIS
#analysis of genres vs. month of rating
edx_genre_separated %>% 
  ggplot(aes(x=month_rating, y=genres)) +
  geom_density_ridges(fill="royalblue4", col="grey") +
  labs(x="Month of Rating (Jan to Dec)", 
       y="Genres",
       title="Density Plots of Genres vs. Month of Rating") +
  theme_bw() 
```

The distribution of genres across months is uniform, with the exception of IMAX ratings being low during February-June. (There are very few IMAX ratings, so that could just be random variability.)     

```{r analysis5e, echo=FALSE, out.width='75%', fig.align = 'center'}
#GENRE ANALYSIS
#analysis of distribution of genres vs. day of rating
edx_genre_separated %>% 
  ggplot(aes(factor(day_rating), fill=genres)) + 
  geom_bar(position = "fill") + 
  scale_fill_manual(values=palette1) +
  theme(legend.title = element_blank()) +
  labs(x="Day of Rating (Mon to Sun)", 
       y="Count",
       title="Distribution of Genres within Rating-Days",
       fill="Genres") +
  guides(fill = guide_legend(nrow = 11)) +
  theme_bw() 
```

The distribution of genres within days of the week is as uniform as can be.    

```{r analysis5f, echo=FALSE, out.width='75%', fig.align = 'center'}
#GENRE ANALYSIS
#analysis of distribution of genres across movie release years
edx_genre_separated %>% 
  ggplot(aes(year_movie, fill=genres)) + 
  geom_density(position="fill", adjust=7) +  
  scale_fill_manual(values=palette1) +
  theme(legend.title = element_blank()) +
  labs(x="Year of Movie Release", 
       y="Density",
       title="Distribution of Genres across Movie Release Years",
       fill="Genres") +
  guides(fill = guide_legend(nrow = 11)) +
  theme_bw() 
```

Film noirs have shown the most dramatic decrease, which is expected since these movies were mostly prevalent in the post-World War II era. IMAX is new technology and has thus propped up very late in the plot. Musicals have witnessed a decline in proportion, although not as dramatic as film noirs. The bright side is that all genres seem to have even distribution in the latest releases.     

```{r analysis5g, echo=FALSE, out.width='75%', fig.align = 'center'}
#GENRE ANALYSIS
#analysis of genre distribution with rating years
edx_genre_separated %>%
  ggplot(aes((years_lapsed+year_movie), y=..count.., col=genres)) + 
  geom_density(adjust=7, size=1.2) + 
  scale_color_manual(values=palette1) +
  theme(legend.title = element_blank()) +
  labs(x="Rating (rounded)", 
       y="Count",
       title="Distribution of Genres with Year of Rating",
       col="Genres") +
  guides(col = guide_legend(nrow = 11)) +
  theme_bw() 
```

Drama and comedy movies witnessed two big surges in 2000 and 2005. In the same years, the other genres also saw surges, but to a lesser extent. Since this is a plot of count and each movie has multiple genres, it may be the case that the same movies are driving the surges in different genres.     

```{r analysis5h, include=FALSE}
#GENRE ANALYSIS
#I will now remove the edx_genre_separated data set and use the genre_stats 
#data set that was generated earlier 
rm(edx_genre_separated)
gc()
load("rda/genres_stats.rda")
```

```{r analysis5i, echo=FALSE, out.width='75%', fig.align = 'center'}
#GENRE ANALYSIS
#analysis of average ratings per genre and the number of such ratings
genres_stats %>% 
  mutate(genres=reorder(genres,avg_rating)) %>% 
  ggplot(aes(genres,avg_rating, size=round(n,-2))) +
  geom_point(col="royalblue4") +
  labs(x="Genres", 
       y="Average Rating",
       title="Average Ratings of Genres",
       size="Number of\nRatings") +
  theme_bw() +
  coord_flip()
```

Film noir has the highest average rating but the number of ratings is quite less. This is likely because users selectively watch such movies because they are classic favourites. Horror movies, unsurprisingly, have the lowest average ratings. All this proves that genre must have an effect of the movie ratings and this will likely be significant in the machine learning algorithms.    

```{r analysis5j, include=FALSE}
#removing genres_stats and clearing memory to prepare for machine learning
rm(genres_stats)
gc()
```

\newpage
# Developing the Recommender System

In this project, I develop two main models:    

1. The first one is a handcrafted hybrid method that models user-movie interactions and movies' attributes. This is done in several intermediate steps, adding one feature at a time.  
2. The second model uses a collaborative filtering method via matrix factorization as done by the *recosystem* package.    

All of the models are developed using only the test set (*edx*) and are tested on the *validation* set.  
The Root Mean Square Error/Deviation (RMSE/RMSD)^[To know more about RMSE and why it's useful, I suggest reading https://towardsdatascience.com/what-does-rmse-really-mean-806b65f2e48e] is used as the sole metric used to judge these models. It is the standard deviation of the prediction errors.  

$$RMSE = \sqrt{\frac{1}{N}\sum_{u,i} ({{{\hat{y_{u,i}}} - {y_{u,i}}}^{2}})}$$ 
$N$: number of user-movie combinations   
${y_{u,i}}$: actual rating for movie $i$ by user $u$  
${\hat{y_{u,i}}}$: predicted rating for movie $i$ by user $u$  

```{r ml-0a, include=FALSE}
#loading the final training and test sets
load("rda/edx_final.rda") #training set
load("rda/validation_final.rda") #test set
```

The following code is used to make a function to compute RMSE for every model:   

```{r ml-0b, results='hide'}
#Defining RMSE:
actual_rating <- validation$rating
RMSE <- function(predicted_rating){
  sqrt(mean((actual_rating - predicted_rating)^2))
}
```

\newpage
# Handcrafted Hybrid Model

## Elementary Model
In this model, the average of all ratings is predicted as the rating for all movies, irrespective of the user and the movie.  

$$Y_{u,i} = \mu + \epsilon_{u,i}$$
$Y_{u,i}$: actual rating for movie $i$ by user $u$  
$\mu$: average of all ratings (predicted "true" rating)  
$\epsilon_{u,i}$: independent errors centered at 0  

The model is implemented in R as follows:    

```{r ml-1a}
#1. Elementary model (using mean)
mu <- mean(edx$rating)

#although this is redundant here, I do it anyway for uniformity across models
predicted_ratings_model1 <- validation %>%
  mutate(pred = mu) %>%
  pull(pred)

#RMSE values for each model are stored for comparison
model1_rmse <- RMSE(predicted_ratings_model1)

#Printing the RMSE
model1_rmse
```

```{r ml-1b, include=FALSE}
#removing variable and clearing memory
rm(predicted_ratings_model1)
gc()
```

The RMSE is quite high, as expected. So, in subsequent steps, we add parameters to model different features so as to account for as much variability as possible.  

\newpage
## Modeling Movie Effects

It is known that some movies are rated higher than others. If you'd like proof anyway, the messy plot below shows the variability of ratings for different mvoieIds.  

```{r ml-2a, echo=FALSE, out.width='75%', fig.align = 'center'}
#checking the distribution of ratings within movie ids
#fct_rev (factor reverse) is used for 0 ratings in the bottom
#direction argument in scale_fill_brewer changes the order of palette colours
edx %>%
  ggplot(aes(movieId, fill=fct_rev(factor(round(rating))))) +
  geom_density(position="fill") + 
  scale_fill_brewer(palette="RdBu", direction=-1) + 
  labs(x="Movie ID", 
       y="Density",
       title="Stacked Density Plot of Movie ID, filled by Rating",
       fill="Rating\n(rounded)") +
  theme_bw()
```

The previous model is thus augmented by adding the term $b_{i}$ to represent average rating for movie $i$.   

$$Y_{u,i} = \mu + b_{i}  + {\epsilon_{u,i}}$$  

The model is implemented as follows:  

```{r ml-2b}
#2. Modeling movie effect:
movie_effect <- edx %>% 
  group_by(movieId) %>%
  summarise(b_i = mean(rating-mu))

#predicting ratings for the validation set
predicted_ratings_model2 <- validation %>%
  left_join(movie_effect, by="movieId") %>%
  mutate(pred = mu + b_i) %>%
  pull(pred)

model2_rmse <- RMSE(predicted_ratings_model2)
model2_rmse
```

```{r ml-2c, include=FALSE}
#removing variable and clearing memory
rm(predicted_ratings_model2)
gc()
```

The RMSE has improved by `r ((model1_rmse-model2_rmse)/model1_rmse)*100`%, but there's still a long way to go.  

```{r ml-2d, echo=FALSE, out.width='75%', fig.align = 'center'}
#variation of movie effect with movie ID
movie_effect %>% 
  ggplot(aes(movieId, b_i)) + 
  geom_point(alpha=0.2, col="royalblue4") +
  geom_smooth(col="black", fill="red") +
  labs(title = "Variation of Movie Effect",
       x = "Movie ID",
       y = "Movie Effect (b_i)",
       caption="Movies affect ratings irregularly.") + 
  scale_x_log10() +
  theme_bw()
```

\newpage
## Modeling User Effects

Users exhibit different rating behaviours. To account for this, the term $b_{u}$ is added to represent user-specific effects for user $u$.  

$$Y_{u,i} = \mu + b_{i} + b_{u} + {\epsilon_{u,i}}$$  

The user rating behaviour doesn't seem as variable as the movie effect, but it'll definitely help improve the model.  

```{r ml-3a, echo=FALSE, out.width='75%', fig.align = 'center'}
#checking the distribution of ratings within user ids
#fct_rev (factor reverse) is used for 0 ratings in the bottom
#direction argument in scale_fill_brewer changes the order of palette colours
edx %>%
  ggplot(aes(userId, fill=fct_rev(factor(round(rating))))) +
  geom_density(position="fill") + 
  scale_fill_brewer(palette="RdBu", direction=-1) + 
  labs(x="User ID", 
       y="Density",
       title="Stacked Density Plot of User ID, filled by Rating",
       fill="Rating\n(rounded)") +
  theme_bw()
```

The model is implemented as follows:  

```{r 3-b}
#3. Modeling user effect:
user_effect <- edx %>%
  left_join(movie_effect, by="movieId") %>%
  group_by(userId) %>%
  summarise(b_u = mean(rating-mu-b_i))

#predicting ratings for the validation set
predicted_ratings_model3 <- validation %>%
  left_join(movie_effect, by="movieId") %>%
  left_join(user_effect, by="userId") %>%
  mutate(pred = mu + b_i + b_u ) %>%
  pull(pred)

model3_rmse <- RMSE(predicted_ratings_model3)
model3_rmse
```

```{r ml-3c, include=FALSE}
#removing variable and clearing memory
rm(predicted_ratings_model3)
gc()
```

The RMSE has improved further by `r ((model2_rmse-model3_rmse)/model2_rmse)*100`%.  

```{r ml-3d, echo=FALSE, out.width='75%', fig.align = 'center'}
#variation of user effect with user ID
user_effect %>% 
  ggplot(aes(userId, b_u)) + 
  geom_point(alpha=0.2, col="royalblue4") +
  geom_smooth(col="black", fill="red") +
  labs(title = "Variation of User Effect",
       x = "User ID",
       y = "User Effect (b_u)",
       caption="Users affect ratings irregularly.") + 
  theme_bw()
```

\newpage
## Modeling 'Month of Rating' Effect

To account for the variation in ratings with the month of the year when rating is given, the term $b_{mr}$ is added to represent month-specific effects for the month of rating $mr$.  

$$Y_{u,i} = \mu + b_{i} + b_{u} + b_{mr} + {\epsilon_{u,i}}$$  

The model is implemented as follows:  

```{r ml-4a}
#4. Modeling 'month of rating' effect:
month_rating_effect <- edx %>%
  left_join(movie_effect, by="movieId") %>%
  left_join(user_effect, by="userId") %>%
  group_by(month_rating) %>%
  summarise(b_mr = mean(rating-mu-b_i-b_u))

#predicting ratings for the validation set
predicted_ratings_model4 <- validation %>%
  left_join(movie_effect, by="movieId") %>%
  left_join(user_effect, by="userId") %>%
  left_join(month_rating_effect, by="month_rating") %>%
  mutate(pred = mu + b_i + b_u + b_mr ) %>%
  pull(pred)

model4_rmse <- RMSE(predicted_ratings_model4)
model4_rmse
```

```{r ml-4b, include=FALSE}
#removing variable and clearing memory
rm(predicted_ratings_model4)
gc()
```

The RMSE has improved further by `r ((model3_rmse-model4_rmse)/model3_rmse)*100`%.  

```{r ml-4c, echo=FALSE, out.width='75%', fig.align = 'center'}
#variation of 'month of rating' effect with month of rating
month_rating_effect %>% 
  ggplot(aes(month_rating, b_mr)) + 
  geom_point(col="royalblue4") +
  geom_smooth(col="black", fill="red") +
  labs(title = "Variation of 'Month of Rating' Effect",
       x = "Month of Rating (Jan to Dec)",
       y = "Month of Rating Effect (b_mr)",
       caption="Slightly higher ratings are given in later months.") + 
  theme_bw()
```

\newpage
## Modeling 'Day of Rating' Effect

To account for the variation in ratings with the day of the week when rating is given, the term $b_{dr}$ is added to represent day-specific effects for the day of rating $dr$.  

$$Y_{u,i} = \mu + b_{i} + b_{u} + b_{mr} + b_{dr} + {\epsilon_{u,i}}$$  

The model is implemented as follows:  

```{r ml-5a}
#4. Modeling 'day of rating' effect:
day_rating_effect <- edx %>%
  left_join(movie_effect, by="movieId") %>%
  left_join(user_effect, by="userId") %>%
  left_join(month_rating_effect, by="month_rating") %>%
  group_by(day_rating) %>%
  summarise(b_dr = mean(rating-mu-b_i-b_u-b_mr))

#predicting ratings for the validation set
predicted_ratings_model5 <- validation %>%
  left_join(movie_effect, by="movieId") %>%
  left_join(user_effect, by="userId") %>%
  left_join(month_rating_effect, by="month_rating") %>%
  left_join(day_rating_effect, by="day_rating") %>%
  mutate(pred = mu + b_i + b_u + b_mr + b_dr) %>%
  pull(pred)

model5_rmse <- RMSE(predicted_ratings_model5)
model5_rmse
```

```{r ml-5b, include=FALSE}
#removing variable and clearing memory
rm(predicted_ratings_model5)
gc()
```

The RMSE has improved further by `r ((model4_rmse-model5_rmse)/model4_rmse)*100`%.  

```{r ml-5c, echo=FALSE, out.width='75%', fig.align = 'center'}
#variation of 'day of rating' effect with day of rating
day_rating_effect %>% 
  ggplot(aes(day_rating, b_dr)) + 
  geom_point(col="royalblue4") +
  geom_smooth(col="black", fill="red") +
  labs(title = "Variation of 'Day of Rating' Effect",
       x = "Day of Rating (Mon to Sun)",
       y = "Day of Rating Effect (b_dr)",
       caption="Lower ratings are given towards the weekend,") + 
  theme_bw()
```

\newpage
## Modeling 'Year of Movie Release' Effect

To account for the variation in ratings with the year in which the movie was released, the term $b_{ym}$ is added to represent year-specific effects for year of movie release $ym$.  

$$Y_{u,i} = \mu + b_{i} + b_{u} + b_{mr} + b_{dr} + b_{ym} + {\epsilon_{u,i}}$$  

The model is implemented as follows:  

```{r ml-6a}
#6. Modeling 'year of movie release' effect:
year_movie_effect <- edx %>%
  left_join(movie_effect, by="movieId") %>%
  left_join(user_effect, by="userId") %>%
  left_join(month_rating_effect, by="month_rating") %>%
  left_join(day_rating_effect, by="day_rating") %>%
  group_by(year_movie) %>%
  summarise(b_ym = mean(rating-mu-b_i-b_u-b_mr-b_dr))

#predicting ratings for the validation set
predicted_ratings_model6 <- validation %>%
  left_join(movie_effect, by="movieId") %>%
  left_join(user_effect, by="userId") %>%
  left_join(month_rating_effect, by="month_rating") %>%
  left_join(day_rating_effect, by="day_rating") %>%
  left_join(year_movie_effect, by="year_movie") %>%
  mutate(pred = mu + b_i + b_u + b_mr + b_dr + b_ym) %>%
  pull(pred)

model6_rmse <- RMSE(predicted_ratings_model6)
model6_rmse
```

```{r ml-6b, include=FALSE}
#removing variable and clearing memory
rm(predicted_ratings_model6)
gc()
```

The RMSE has improved further by `r ((model5_rmse-model6_rmse)/model5_rmse)*100`%.  

```{r ml-6c, echo=FALSE, out.width='75%', fig.align = 'center'}
#variation of 'year of movie release' effect with
#year of movie release
year_movie_effect %>% 
  ggplot(aes(year_movie, b_ym)) + 
  geom_point(col="royalblue4") +
  geom_smooth(col="black", fill="red") +
  labs(title = "Variation of 'Year of Movie Release' Effect",
       x = "Year of Movie Release",
       y = "Year of Movie Release Effect (b_ym)",
       caption="Older movies are rated higher than newer ones.") + 
  theme_bw()
```

\newpage
## Modeling 'Years Lapsed' Effect

To account for the variation in ratings with the years lapsed between rating and movie release, the term $b_{yl}$ is added to represent year-gap-specific effects for years lapsed $yl$.  

$$Y_{u,i} = \mu + b_{i} + b_{u} + b_{mr} + b_{dr} + b_{ym} + b_{yl} + {\epsilon_{u,i}}$$  

The model is implemented as follows:  

```{r ml-7a}
#7. Modeling 'years lapsed' effect:
years_lapsed_effect <- edx %>%
  left_join(movie_effect, by="movieId") %>%
  left_join(user_effect, by="userId") %>%
  left_join(month_rating_effect, by="month_rating") %>%
  left_join(day_rating_effect, by="day_rating") %>%
  left_join(year_movie_effect, by="year_movie") %>% 
  group_by(years_lapsed) %>%
  summarise(b_yl = mean(rating-mu-b_i-b_u-b_mr-b_dr-b_ym))

#predicting ratings for the validation set
predicted_ratings_model7 <- validation %>%
  left_join(movie_effect, by="movieId") %>%
  left_join(user_effect, by="userId") %>%
  left_join(month_rating_effect, by="month_rating") %>%
  left_join(day_rating_effect, by="day_rating") %>%
  left_join(year_movie_effect, by="year_movie") %>%
  left_join(years_lapsed_effect, by="years_lapsed") %>%
  mutate(pred = mu + b_i + b_u + b_mr + b_dr + b_ym + b_yl) %>%
  pull(pred)

model7_rmse <- RMSE(predicted_ratings_model7)
model7_rmse
```

```{r ml-7b, include=FALSE}
#removing variable and clearing memory
rm(predicted_ratings_model7)
gc()
```

The RMSE has improved further by `r ((model6_rmse-model7_rmse)/model6_rmse)*100`%.  

```{r ml-7c, echo=FALSE, out.width='75%', fig.align = 'center'}
#variation of 'years lapsed' effect with years lapsed
years_lapsed_effect %>% 
  ggplot(aes(years_lapsed, b_yl)) + 
  geom_point(col="royalblue4") +
  geom_smooth(col="black", fill="red") +
  labs(title = "Variation of 'Years Lapsed' Effect",
       x = "Years Lapsed",
       y = "Years Lapsed Effect (b_yl)",
       caption="Years lapsed affect movie ratings irregularly.") + 
  theme_bw()
```

\newpage
## Modeling Genre Effect

It was seen towards the end of the genre analysis that some genres receive higher average ratings than others. Earlier, a column was created with the maximum value of the average ratings of the genres of each movie. To account for the variation in ratings with the genres, the term $b_{g}$ is added to represent genre-specific effects for the max average genre rating $g$.  

$$Y_{u,i} = \mu + b_{i} + b_{u} + b_{mr} + b_{dr} + b_{ym} + b_{yl} + b_{g} + {\epsilon_{u,i}}$$  

The model is implemented as follows:  

```{r ml-8a}
#8. Modeling genre effect:
genre_effect <- edx %>%
  left_join(movie_effect, by="movieId") %>%
  left_join(user_effect, by="userId") %>%
  left_join(month_rating_effect, by="month_rating") %>%
  left_join(day_rating_effect, by="day_rating") %>%
  left_join(year_movie_effect, by="year_movie") %>%
  left_join(years_lapsed_effect, by="years_lapsed") %>% 
  group_by(genres_rating) %>%
  summarise(b_g = mean(rating-mu-b_i-b_u-b_mr-b_dr-b_ym-b_yl))

#predicting ratings for the validation set
predicted_ratings_model8 <- validation %>%
  left_join(movie_effect, by="movieId") %>%
  left_join(user_effect, by="userId") %>%
  left_join(month_rating_effect, by="month_rating") %>%
  left_join(day_rating_effect, by="day_rating") %>%
  left_join(year_movie_effect, by="year_movie") %>%
  left_join(years_lapsed_effect, by="years_lapsed") %>%
  left_join(genre_effect, by="genres_rating") %>%
  mutate(pred = mu + b_i + b_u + b_mr + b_dr + b_ym + b_yl + b_g) %>%
  pull(pred)

model8_rmse <- RMSE(predicted_ratings_model8)
model8_rmse
```

```{r ml-8b, include=FALSE}
#removing variable and clearing memory
rm(predicted_ratings_model8)
gc()
```

The RMSE has improved further by `r ((model7_rmse-model8_rmse)/model7_rmse)*100`%.

```{r ml-8c, echo=FALSE, out.width='75%', fig.align = 'center'}
#variation of genre effect with max avg genre rating
genre_effect %>% 
  ggplot(aes(genres_rating, b_g)) + 
  geom_point(col="royalblue4") +
  geom_smooth(col="black", fill="red") +
  labs(title = "Variation of Genre Effect",
       x = "Max Average Genre Rating",
       y = "Genre Effect (b_g)",
       caption="Genres affect movie ratings irregularly.") + 
  theme_bw()
```

\newpage
## Regularized Model

While managing to decrease the RMSE, it's still not perfect. A reason could be that there are several large effects formed by small sample sizes. The data is not uniformly distributed. Thus, regularization^[To read more about regularization, I suggest https://towardsdatascience.com/regularization-in-machine-learning-76441ddcf99a] is introduced to constrain the variability of effects and consequently penalize large effects that are formed using small sample sizes.  

The new equation adds a penalty to the least squares equation that was being minimized earlier.    
Least Squares Equation:   
$$\sum_{u,i} ({y_{u,i}} - \mu - b_{i} - b_{u} - b_{mr} - b_{dr} - b_{ym} - b_{yl} - b_{g})^{2}$$  
New Equation to be minimized:  
$$\sum_{u,i} (y_{u,i} - \mu - b_{i} - b_{u} - b_{mr} - b_{dr} - b_{ym} - b_{yl} - b_{g})^{2} + 
 \lambda \left(\sum_{i}b_{i}^{2} + \sum_{u}b_{u}^{2} + \sum_{mr}b_{mr}^{2} + \sum_{dr}b_{dr}^{2} + \sum_{ym}b_{ym}^{2} + \sum_{yl}b_{yl}^{2} + \sum_{g}b_{g}^{2}\right)$$  

The first term is the sum of the squares and the second is a penalty that gets larger when many effects are large. Calculus is used to finally show that the equation is minimized if effects are computed after dividing by sample size and penalty $\lambda$, instead of just the sample size as was done earlier. This way, when the sample size is large, the penalty is ignored and when the sample size is small, $\lambda$ shrinks the effect.   

$\lambda$ needs to be tuned and cross validation will be used to do so.    

The *edx* set is split for cross validation as follows:  

```{r ml-9a, results='hide'}
#PREPARING FOR CROSS VALIDATION
set.seed(1, sample.kind="Rounding") 
#if using R 3.5 or earlier, use `set.seed(1)`

#Creating the test index
edx_test_index <- createDataPartition(
  edx$rating, times=1, p=0.2, list = FALSE)

#Splitting the edx set for cross validation
edx_train <- edx[-edx_test_index,] #used for training
edx_test <- edx[edx_test_index,] #used for tuning

#To ensure only those movies and users are present in 
#edx_test for which there are observations in edx_train
edx_test <- edx_test %>% 
  semi_join(edx_train, by = "movieId") %>%
  semi_join(edx_train, by = "userId")
```

The process for computing the RMSEs for a range of values of $\lambda$ is given below:  

```{r ml-9b, results='hide'}
#Defining a sequence of values of lambda(l) to check RMSE
l <- seq(1, 10, 1)

#Applying lambda values and checking RMSE in edx_test:
rmses <- sapply(l, function(l){
  #Mean Ratings:
  mu <- mean(edx_train$rating)
  
  #Movie Effect:
  movie_effect <- edx_train %>% 
    group_by(movieId) %>%
    summarise(b_i = sum(rating-mu)/(n()+l))
  
  #User Effect
  user_effect <- edx_train %>%
    left_join(movie_effect, by="movieId") %>%
    group_by(userId) %>%
    summarise(b_u = sum(rating-mu-b_i)/(n()+l))
  
  #Month of Rating Effect:
  month_rating_effect <- edx_train %>%
    left_join(movie_effect, by="movieId") %>%
    left_join(user_effect, by="userId") %>%
    group_by(month_rating) %>%
    summarise(b_mr = sum(rating-mu-b_i-b_u)/(n()+l))
  
  #Day of Rating Effect:
  day_rating_effect <- edx_train %>%
    left_join(movie_effect, by="movieId") %>%
    left_join(user_effect, by="userId") %>%
    left_join(month_rating_effect, by="month_rating") %>%
    group_by(day_rating) %>%
    summarise(b_dr = sum(rating-mu-b_i-b_u-b_mr)/(n()+l))
  
  #Year of Movie Release Effect:
  year_movie_effect <- edx_train %>%
    left_join(movie_effect, by="movieId") %>%
    left_join(user_effect, by="userId") %>%
    left_join(month_rating_effect, by="month_rating") %>%
    left_join(day_rating_effect, by="day_rating") %>%
    group_by(year_movie) %>%
    summarise(b_ym =sum(rating-mu-b_i-b_u-b_mr-b_dr)/(n()+l))
  
  #Years Lapsed Effect:
  years_lapsed_effect <- edx_train %>%
    left_join(movie_effect, by="movieId") %>%
    left_join(user_effect, by="userId") %>%
    left_join(month_rating_effect, by="month_rating") %>%
    left_join(day_rating_effect, by="day_rating") %>%
    left_join(year_movie_effect, by="year_movie") %>% 
    group_by(years_lapsed) %>%
    summarise(b_yl = sum(rating-mu-b_i-b_u-b_mr-b_dr-b_ym)/(n()+l))
  
  #Genre Effect:
  genre_effect <- edx_train %>%
    left_join(movie_effect, by="movieId") %>%
    left_join(user_effect, by="userId") %>%
    left_join(month_rating_effect, by="month_rating") %>%
    left_join(day_rating_effect, by="day_rating") %>%
    left_join(year_movie_effect, by="year_movie") %>% 
    left_join(years_lapsed_effect, by="years_lapsed") %>%
    group_by(genres_rating) %>%
    summarise(b_g = sum(rating-mu-b_i-b_u-b_mr-b_dr-b_ym-b_yl)/(n()+l))
  
  #Applying the models on edx_test set:
  predicted_ratings <- edx_test %>%
    left_join(movie_effect, by="movieId") %>%
    left_join(user_effect, by="userId") %>%
    left_join(month_rating_effect, by="month_rating") %>%
    left_join(day_rating_effect, by="day_rating") %>%
    left_join(year_movie_effect, by="year_movie") %>%
    left_join(years_lapsed_effect, by="years_lapsed") %>%
    left_join(genre_effect, by="genres_rating") %>%
    mutate(pred = mu + b_i + b_u + b_mr + b_dr + b_ym + b_yl + b_g) %>%
    pull(pred)
  
  #Calculating the RMSE:
  sqrt(mean((edx_test$rating - predicted_ratings)^2))
})
```

The resulting RMSEs are plotted against $\lambda$ to find the value of $\lambda$ which best minimizes RMSE in the *edx_test* set.    

```{r ml-9c, echo=FALSE, out.width="75%", fig.align = 'center'}
#plotting RMSE against lambda (l)
data.frame(l = l, RMSE = rmses) %>%
  ggplot(aes(l, RMSE)) + 
  geom_point(col="royalblue4") + 
  geom_line(col="royalblue4")  + 
  labs(title = "Variation of RMSE with l (lambda)",
       x = "l (lambda)",
       y = "RMSE") +
  theme_bw()
```

```{r ml-9d, include=FALSE}
#Removing variables not needed anymore and clearing memory
rm(edx_test_index, edx_test, edx_train)
gc()
```

The value of $\lambda$ that minimizes the RMSE is `r l[which.min(rmses)]`. This will be used to make our final model as follows:  

```{r ml-9e, results='hide'}

#storing the l which minimized RMSE on cross valdiation
l <- l[which.min(rmses)]

#Mean Ratings:
mu <- mean(edx$rating)

#Movie Effect:
movie_effect <- edx %>% 
  group_by(movieId) %>%
  summarise(b_i = sum(rating-mu)/(n()+l))

#User Effect:
user_effect <- edx %>%
  left_join(movie_effect, by="movieId") %>%
  group_by(userId) %>%
  summarise(b_u = sum(rating-mu-b_i)/(n()+l))

#Month of Rating Effect:
month_rating_effect <- edx %>%
  left_join(movie_effect, by="movieId") %>%
  left_join(user_effect, by="userId") %>%
  group_by(month_rating) %>%
  summarise(b_mr = sum(rating-mu-b_i-b_u)/(n()+l))

#Day of Rating Effect:
day_rating_effect <- edx %>%
  left_join(movie_effect, by="movieId") %>%
  left_join(user_effect, by="userId") %>%
  left_join(month_rating_effect, by="month_rating") %>%
  group_by(day_rating) %>%
  summarise(b_dr = sum(rating-mu-b_i-b_u-b_mr)/(n()+l))

#Year of Movie Release Effect:
year_movie_effect <- edx %>%
  left_join(movie_effect, by="movieId") %>%
  left_join(user_effect, by="userId") %>%
  left_join(month_rating_effect, by="month_rating") %>%
  left_join(day_rating_effect, by="day_rating") %>%
  group_by(year_movie) %>%
  summarise(b_ym = sum(rating-mu-b_i-b_u-b_mr-b_dr)/(n()+l))

#Years Lapsed Effect:
years_lapsed_effect <- edx %>%
  left_join(movie_effect, by="movieId") %>%
  left_join(user_effect, by="userId") %>%
  left_join(month_rating_effect, by="month_rating") %>%
  left_join(day_rating_effect, by="day_rating") %>%
  left_join(year_movie_effect, by="year_movie") %>% 
  group_by(years_lapsed) %>%
  summarise(b_yl = sum(rating-mu-b_i-b_u-b_mr-b_dr-b_ym)/(n()+l))

#Genre Effect:
genre_effect <- edx %>%
  left_join(movie_effect, by="movieId") %>%
  left_join(user_effect, by="userId") %>%
  left_join(month_rating_effect, by="month_rating") %>%
  left_join(day_rating_effect, by="day_rating") %>%
  left_join(year_movie_effect, by="year_movie") %>%
  left_join(years_lapsed_effect, by="years_lapsed") %>%
  group_by(genres_rating) %>%
  summarise(b_g = sum(rating-mu-b_i-b_u-b_mr-b_dr-b_ym-b_yl)/(n()+l))

#Applying the model on the validation set:
predicted_ratings_reg <- validation %>%
  left_join(movie_effect, by="movieId") %>%
  left_join(user_effect, by="userId") %>%
  left_join(month_rating_effect, by="month_rating") %>%
  left_join(day_rating_effect, by="day_rating") %>%
  left_join(year_movie_effect, by="year_movie") %>%
  left_join(years_lapsed_effect, by="years_lapsed") %>%
  left_join(genre_effect, by="genres_rating") %>%
  mutate(pred = mu + b_i + b_u + b_mr + b_dr + b_ym + b_yl + b_g) %>%
  pull(pred) 

```

The final RMSE is:  

```{r ml-9f}
#Calculating the RMSE:
rmse_reg <- RMSE(predicted_ratings_reg)
rmse_reg
```

```{r ml-9g, include=FALSE}
#removing variables not needed anymore and clearing memory
rm(predicted_ratings_reg, movie_effect, user_effect, month_rating_effect, 
   day_rating_effect, year_movie_effect, years_lapsed_effect, genre_effect, mu, l)
gc()
```

Thus regularization reduces the RMSE by `r ((model8_rmse-rmse_reg)/model8_rmse)*100`%.  

\newpage
# Collaborative Filtering Model

A collaborative filtering model is implemented by using matrix factorization as done by the *recosystem*^[The *recosystem* package does matrix factorization specifically for recommender systems, i.e. specifically for settings in which the user-movie interaction matrix has many missing values. It’s written by experts in numerical matrix factorization, and features a number of useful options. Source: http://heather.cs.ucdavis.edu/~matloff/189G/Supplements/Supp02182020.pdf] package. In this, only user-movie interactions are used to model the system, not movie attributes.    

In the handcrafted model, user-specific and movie-specific differences were accounted for, but an important source of variation was ignored. Groups of movies and groups of users have similar rating patterns.This is handled by converting the ratings data into a matrix such that each user gets a row and  each movie gets a column. Matrix factorization is used to solve this complex user-movie interaction matrix by decomposing it into a product of two smaller matrices.     

The code to implement matrix factorization using recosystem is as follows:  

```{r collab-filter, results='hide'}
set.seed(1, sample.kind="Rounding") 
#if using R 3.5 or earlier, use `set.seed(1)

#converting the 'edx' and 'validation' sets into recosystem-compatible forms 
#data_memory function specifies a data set from R objects
edx_reco <-  with(edx, data_memory(
  user_index = userId,
  item_index = movieId, 
  rating = rating))
validation_reco  <-  with(validation, data_memory(
  user_index = userId,
  item_index = movieId,
  rating = rating))

#creating the recosystem object
r <-  recosystem::Reco()

#training the model with default parameters
r$train(edx_reco)

#getting the predicted ratings
#out_memory is used to return the result as an R object
predicted_ratings_reco <- r$predict(validation_reco, out_memory())
```

The RMSE for the predictions of *recosystem* is:    

```{r collab-filter2}
#calculating the RMSE
rmse_reco <- RMSE(predicted_ratings_reco)
rmse_reco
```

This is an improvement of `r ((rmse_reg-rmse_reco)/rmse_reg)*100`% over the final handcrafted model.    

```{r collab-filter3, include=FALSE}
#removing variables not needed anymore and clearing memory 
rm(predicted_ratings_reco, r, edx_reco, validation_reco, actual_rating)
gc()
```

\newpage
# Results

The handcrafted hybrid model shows great promise and is a great way to understand underlying trends. But the genius of the *recosystem* package is unparalleled. Even without tuning the parameters and sticking to defaults, an RMSE of `r rmse_reco` was achieved.  

```{r results, echo=FALSE, out.width="75%", fig.align = 'center'}

#making a data frame of the RMSEs of all the models
models <- c("Elementary Model", 
            "Movie Effect +",
            "User Effect +",
            "Month of Rating Effect +",
            "Day of Rating Effect +",
            "Year of Movie Release Effect +",
            "Years Lapsed Effect +",
            "Genre Effect +", 
            "Final Hybrid Model", 
            "Recosystem Model")
rmse_values <- c(model1_rmse, model2_rmse, model3_rmse, 
                 model4_rmse, model5_rmse, model6_rmse, 
                 model7_rmse, model8_rmse, 
                 rmse_reg, rmse_reco)

rmse_results <- data.frame(models, rmse_values)

#plotting the RMSEs
rmse_results %>% 
  mutate(models=reorder(models,-rmse_values)) %>%
  ggplot(aes(
    models, rmse_values, label=round(rmse_values,5))) +
  geom_col(fill="royalblue4", width=0.3) +
  geom_text(position = position_nudge(y = 0.126)) +
  coord_flip() +
  labs(title="RMSEs of the Models",
       x="Model",
       y="RMSE")
```

\newpage
# Conclusion and Future Outlook

In this project, the *movielens* data set was explored in detail, with an extra fun genre analysis. To predict movie ratings for a user and movie, two different algorithms have been constructed with the lowest reported RMSE being `r rmse_reco`. For the first model, a step-by-step development process was shown. The second model involved an advanced method, so I stuck to the defaults. These models have aided a relatively successful movie recommendation system.   

That said, with machine learning, the more the merrier. More data, more models and more tuning will unquestionably better the system. It must be noted that the computational time was quite large, and the processor RAM requirements are high. Optimization can be considered in the future.